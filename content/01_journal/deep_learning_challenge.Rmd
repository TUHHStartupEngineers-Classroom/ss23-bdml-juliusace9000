#Final Challenge

At first, the data has to be loaded.

```{r}

library(tidyverse)
library(keras)
library(lime)
library(rsample)
library(recipes)
library(yardstick)
library(corrr)

churn_data_raw <- read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")

glimpse(churn_data_raw)
```
Then the data gets pruned.
```{r}
# Prune the data
churn_data_tbl <- churn_data_raw %>%
  # Remove the "customerID" column
  select(-customerID) %>%
  # Remove rows with NA values in "TotalCharges" column
  drop_na(TotalCharges) %>%
  # Move the target column to the first position
  select(Churn, everything())

# View the resulting table
head(churn_data_tbl)

```
The dataset is split into a test and a training set.
```{r}
# Split test/training sets
set.seed(69)
train_test_split <- initial_split(churn_data_tbl, prop = 0.8)
train_test_split

# Retrieve train and test sets
train_tbl <- training(train_test_split)
test_tbl  <- testing(train_test_split)
```
```{r}
churn_data_tbl %>% ggplot(aes(x = tenure)) + 
  geom_histogram(bins = 6, color = "white", fill =  "#2DC6D6") +
  labs(
    title = "Tenure Counts With Six Bins",
    x     = "tenure (month)"
  )

train_tbl %>%
    select(Churn, TotalCharges) %>%
    mutate(
        Churn = Churn %>% as.factor() %>% as.numeric(),
        LogTotalCharges = log(TotalCharges)
        ) %>%
    correlate() %>%
    focus(Churn) %>%
    fashion()
```

##One-Hot Encoding
```{r}
churn_data_tbl %>% 
        pivot_longer(cols      = c(Contract, InternetService, MultipleLines, PaymentMethod), 
                     names_to  = "feature", 
                     values_to = "category") %>% 
        ggplot(aes(category)) +
          geom_bar(fill = "#2DC6D6") +
          facet_wrap(~ feature, scales = "free") +
          labs(
            title = "Features with multiple categories: Need to be one-hot encoded"
          ) +
          theme(axis.text.x = element_text(angle = 25, 
                                           hjust = 1))
```
#Proprocessing the Data
```{r}
rec_obj <- recipe(Churn ~ ., data = train_tbl) %>%
    step_rm(Churn) %>% 
    step_discretize(tenure, options = list(cuts = 6)) %>%
    step_log(TotalCharges) %>%
    step_dummy(all_nominal(), -all_outcomes(), one_hot = T) %>%
    step_center(all_predictors(), -all_outcomes()) %>%
    step_scale(all_predictors(), -all_outcomes()) %>%
    prep(data = train_tbl)
```
#Bake the predictors
```{r}
# Bake the predictors
x_train_tbl <- bake(rec_obj, new_data = train_tbl)
x_test_tbl  <- bake(rec_obj, new_data = test_tbl)
```
#Response Variables for training and testing set
```{r}
# Response variables for training and testing sets
y_train_vec <- ifelse(train_tbl$Churn == "Yes", 1, 0)
y_test_vec  <- ifelse(test_tbl$Churn == "Yes", 1, 0)
```
#Building the AI Model
```{r}
# Building our Artificial Neural Network
model_keras <- keras_model_sequential()

model_keras %>% 
    # First hidden layer
    layer_dense(
        units              = 16, 
        kernel_initializer = "uniform", 
        activation         = "relu", 
        input_shape        = ncol(x_train_tbl)) %>% 
    # Dropout to prevent overfitting
    layer_dropout(rate = 0.1) %>%
    # Second hidden layer
    layer_dense(
        units              = 16, 
        kernel_initializer = "uniform", 
        activation         = "relu") %>% 
    # Dropout to prevent overfitting
    layer_dropout(rate = 0.1) %>%
    # Output layer
    layer_dense(
        units              = 1, 
        kernel_initializer = "uniform", 
        activation         = "sigmoid") %>% 
    # Compile ANN
    compile(
        optimizer = 'adam',
        loss      = 'binary_crossentropy',
        metrics   = c('accuracy')
    )
model_keras
```

# Fit the keras model to the training data
```{r}
x_train_matrix = as.matrix(x_train_tbl)
y_train_matrix = as.matrix(y_train_vec)
x_test_matrix = as.matrix(x_test_tbl)
y_test_matrix = as.matrix(y_test_vec)
fit_keras <-  fit(
    model_keras,
    x = x_train_matrix,
    y = y_train_matrix,
    epochs = 35,
    batch_size = 50,
    validation_data = list(x_test_matrix, y_test_matrix),
    validation_split = 0.3
  )
fit_keras
```
##Plotting of the training/validation accuracy
```{r}
# Plot the training/validation history of our Keras model
#plot(fit_keras) +
#  labs(title = "Deep Learning Training Results") +
#  theme(legend.position  = "bottom", 
#        strip.placement  = "inside",
#        strip.background = element_rect(fill = "#grey"))
```

#Predictions
```{r}
# Predicted Class
yhat_keras_class_vec <- predict(model_keras, as.matrix(x_test_tbl)) %>%
  as.vector() %>%
  round()

# Predicted Class Probability
yhat_keras_prob_vec  <- predict(model_keras, as.matrix(x_test_tbl)) %>%
    as.vector()
```
# Estimations
```{r}
estimates_keras_tbl <- tibble(
  truth = as.factor(y_test_vec) %>% fct_recode(Yes = "1", No = "0"),
  estimate = as.factor(yhat_keras_class_vec) %>% fct_recode(Yes = "1", No = "0"),
  class_prob = yhat_keras_prob_vec
)

estimates_keras_tbl
```
##confusion Table
```{r}
# Confusion Table
confusion_table <- conf_mat(data = estimates_keras_tbl, truth, estimate)

confusion_table

# Accuracy
accuracy_result <- accuracy(data = estimates_keras_tbl, truth, estimate)

accuracy_result

# AUC
auc_result <- roc_auc(data = estimates_keras_tbl, truth, class_prob, event_level = "second")

auc_result
```
# Precision
```{r}
# Precision
precision_result <- precision(data = estimates_keras_tbl, truth, estimate)

# Recall
recall_result <- recall(data = estimates_keras_tbl, truth, estimate)

# Combine precision and recall results into a tibble
precision_recall_tbl <- tibble(
  precision = precision_result$.estimate,
  recall = recall_result$.estimate
)

precision_recall_tbl

# F1-Statistic
estimates_keras_tbl %>% f_meas(truth, estimate, beta = 1)
```
#LIME
```{r}
# F1-Statistic
estimates_keras_tbl %>% f_meas(truth, estimate, beta = 1)

# Setup lime::model_type() function for keras
model_type.keras.engine.sequential.Sequential  <- function(x, ...) {
    return("classification")
}

# Setup lime::predict_model() function for keras
predict_model.keras.engine.sequential.Sequential <- function(x, newdata, type, ...) {
    pred <- predict(object = x, x = as.matrix(newdata))
    return(data.frame(Yes = pred, No = 1 - pred))
}

library(lime)
# Test our predict_model() function
predict_model(x = model_keras, newdata = x_test_tbl, type = 'raw') %>%
    tibble::as_tibble()

# Run lime() on training set
# Run lime() on training set
explainer <- lime::lime(
  x = x_train_tbl,
  model = model_keras,
  bin_continuous = FALSE
)

# Run explain() on test data

x_test_df <- as.data.frame(x_test_tbl)

explanation <- lime::explain(
  x = x_test_df[1:10, ],  # Specify all rows and desired columns
  explainer = explainer,
  n_labels = 2,
  n_features = 50
)

plot_features(explanation)
plot_explanations(explanation)
```
#Correlation Analysis
```{r}
# Feature correlations to Churn
corrr_analysis <- x_train_tbl %>%
    mutate(Churn = y_train_vec) %>%
    correlate() %>%
    focus(Churn) %>%
    rename(feature = rowname) %>%
    arrange(abs(Churn)) %>%
    mutate(feature = as_factor(feature)) 
corrr_analysis
```
